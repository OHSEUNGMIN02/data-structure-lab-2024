# -*- coding: utf-8 -*-
"""Tracking

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNhpASqriTybmMtU1Pji-IzFsN4VP49-
"""

# 📦 1. 설치
!git clone https://github.com/ultralytics/yolov5.git
!pip install -r yolov5/requirements.txt
!pip install deep_sort_realtime

# 📁 2. YOLOv5 모델 로드 (torch.hub 사용)
import cv2
import torch
import numpy as np
import glob
import os
from deep_sort_realtime.deepsort_tracker import DeepSort
from google.colab import files

# 📤 3. 이미지 여러 장 업로드
print("📤 이미지들을 업로드하세요 (예: frame001.jpg, frame002.jpg 등)")
uploaded = files.upload()

# 업로드된 파일 목록 정렬
image_files = sorted([f for f in uploaded.keys() if f.lower().endswith(('.jpg', '.png'))])

# 비디오로 변환 (10fps 기준)
first_frame = cv2.imread(image_files[0])
h, w, _ = first_frame.shape
video_path = 'temp_input_video.mp4'
out_vid = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), 10, (w, h))
for f in image_files:
    frame = cv2.imread(f)
    out_vid.write(frame)
out_vid.release()
print("🎞️ 이미지 → temp_input_video.mp4 변환 완료")

# 🎯 YOLOv5 모델 로드 (torch.hub)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True).to(device)
model.conf = 0.4
model.iou = 0.5

# 🎯 Deep SORT 초기화
tracker = DeepSort(max_age=30, n_init=3, max_cosine_distance=0.4)

# 📽️ 비디오 열기 및 출력 설정
cap = cv2.VideoCapture(video_path)
width, height = int(cap.get(3)), int(cap.get(4))
fps = cap.get(cv2.CAP_PROP_FPS)
out = cv2.VideoWriter('output_tracking.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

print("\n🚀 추적 시작...")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret or frame is None or frame.size == 0:
        break

    # 객체 탐지
    results = model(frame)
    detections = results.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2, conf, cls]

    # Deep SORT 입력 준비
    track_inputs = []
    for det in detections:
        x1, y1, x2, y2, conf, cls = det
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])

        # 🛡️ 경계 보정
        x1 = max(0, min(x1, frame.shape[1] - 1))
        y1 = max(0, min(y1, frame.shape[0] - 1))
        x2 = max(0, min(x2, frame.shape[1] - 1))
        y2 = max(0, min(y2, frame.shape[0] - 1))
        if x2 - x1 < 3 or y2 - y1 < 3:
            continue

        bbox = [x1, y1, x2 - x1, y2 - y1]  # [x, y, w, h]
        track_inputs.append((bbox, conf, f'class_{int(cls)}'))

    tracks = []
    if len(track_inputs) > 0:
        try:
            tracks = tracker.update_tracks(track_inputs, frame=frame)
        except Exception as e:
            print("⚠️ Deep SORT 오류 발생, 건너뜀:", e)
            tracks = []

    for track in tracks:
        if not track.is_confirmed():
            continue
        track_id = track.track_id
        x1, y1, x2, y2 = map(int, track.to_ltrb())
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f'ID {track_id}', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    out.write(frame)

cap.release()
out.release()
print("\n✅ 추적 완료! 결과 파일: output_tracking.mp4")

from google.colab import files
files.download("output_tracking.mp4")