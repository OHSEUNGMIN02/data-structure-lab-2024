# -*- coding: utf-8 -*-
"""Tracking

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNhpASqriTybmMtU1Pji-IzFsN4VP49-
"""

# ğŸ“¦ 1. YOLOv5 + Deep SORT ì„¤ì¹˜
!git clone https://github.com/ultralytics/yolov5.git
!pip install -r yolov5/requirements.txt
!pip install deep_sort_realtime

# ğŸ“ 2. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”©
import cv2
import torch
import numpy as np
from yolov5.models.common import DetectMultiBackend
from yolov5.utils.general import non_max_suppression
from deep_sort_realtime.deepsort_tracker import DeepSort

# ğŸ“¤ 3. Colabì—ì„œ ë™ì˜ìƒ ì—…ë¡œë“œ
from google.colab import files
uploaded = files.upload()  # input_video.mp4 ì—…ë¡œë“œ

video_path = list(uploaded.keys())[0]  # ì²« ë²ˆì§¸ ì—…ë¡œë“œëœ íŒŒì¼ ì‚¬ìš©

# ğŸ¯ 4. YOLOv5 ëª¨ë¸ ë¡œë“œ
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = DetectMultiBackend('yolov5s.pt', device=device)
model.eval()

# ğŸ¯ 5. Deep SORT ì´ˆê¸°í™”
tracker = DeepSort(max_age=30, n_init=3, max_cosine_distance=0.4)

# ğŸ“½ï¸ 6. ë¹„ë””ì˜¤ ì—´ê¸° ë° ì¶œë ¥ ì„¤ì •
cap = cv2.VideoCapture(video_path)
width, height = int(cap.get(3)), int(cap.get(4))
fps = cap.get(cv2.CAP_PROP_FPS)
out = cv2.VideoWriter('output_tracking.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

print("\nğŸš€ ì¶”ì  ì‹œì‘...")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret or frame is None or frame.size == 0:
        break

    # YOLOv5 ì…ë ¥ ì „ì²˜ë¦¬
    img = cv2.resize(frame, (640, 640))
    img_rgb = img[:, :, ::-1].copy()
    img_tensor = torch.from_numpy(img_rgb).float().permute(2, 0, 1) / 255.0
    img_tensor = img_tensor.unsqueeze(0).to(device)

    # ê°ì²´ íƒì§€
    pred = model(img_tensor)
    pred = non_max_suppression(pred, conf_thres=0.4, iou_thres=0.5)[0]

    # Deep SORT ì…ë ¥ ì¤€ë¹„
    track_inputs = []
    if pred is not None and len(pred):
        if isinstance(pred, torch.Tensor):
            pred = pred.cpu().numpy()

        for *xyxy, conf, cls in pred:
            x1, y1, x2, y2 = map(int, xyxy)

            # ğŸ›¡ï¸ ê²½ê³„ ê°’ ë³´ì •
            x1 = max(0, min(x1, frame.shape[1] - 1))
            y1 = max(0, min(y1, frame.shape[0] - 1))
            x2 = max(0, min(x2, frame.shape[1] - 1))
            y2 = max(0, min(y2, frame.shape[0] - 1))

            # ë„ˆë¬´ ì‘ì€ bboxëŠ” ê±´ë„ˆëœ€
            if x2 - x1 < 3 or y2 - y1 < 3:
                continue

            bbox = [x1, y1, x2 - x1, y2 - y1]
            track_inputs.append((bbox, float(conf), f'class_{int(cls)}'))

    # Deep SORT ì—…ë°ì´íŠ¸
    tracks = []
    if len(track_inputs) > 0:
        try:
            tracks = tracker.update_tracks(track_inputs, frame=frame)
        except Exception as e:
            print("âš ï¸ Deep SORT ì˜¤ë¥˜ ë°œìƒ, ê±´ë„ˆëœ€:", e)
            tracks = []

    # ì‹œê°í™”
    for track in tracks:
        if not track.is_confirmed():
            continue
        track_id = track.track_id
        x1, y1, x2, y2 = map(int, track.to_ltrb())
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f'ID {track_id}', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    out.write(frame)

cap.release()
out.release()
print("\nâœ… ì¶”ì  ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: output_tracking.mp4")

from google.colab import files
files.download("output_tracking.mp4")