# -*- coding: utf-8 -*-
"""Tracking

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNhpASqriTybmMtU1Pji-IzFsN4VP49-
"""

# 📦 1. YOLOv5 + Deep SORT 설치
!git clone https://github.com/ultralytics/yolov5.git
!pip install -r yolov5/requirements.txt
!pip install deep_sort_realtime

# 📁 2. 기본 라이브러리 로딩
import cv2
import torch
import numpy as np
from yolov5.models.common import DetectMultiBackend
from yolov5.utils.general import non_max_suppression
from deep_sort_realtime.deepsort_tracker import DeepSort

# 📤 3. Colab에서 동영상 업로드
from google.colab import files
uploaded = files.upload()  # input_video.mp4 업로드

video_path = list(uploaded.keys())[0]  # 첫 번째 업로드된 파일 사용

# 🎯 4. YOLOv5 모델 로드
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = DetectMultiBackend('yolov5s.pt', device=device)
model.eval()

# 🎯 5. Deep SORT 초기화
tracker = DeepSort(max_age=30, n_init=3, max_cosine_distance=0.4)

# 📽️ 6. 비디오 열기 및 출력 설정
cap = cv2.VideoCapture(video_path)
width, height = int(cap.get(3)), int(cap.get(4))
fps = cap.get(cv2.CAP_PROP_FPS)
out = cv2.VideoWriter('output_tracking.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

print("\n🚀 추적 시작...")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret or frame is None or frame.size == 0:
        break

    # YOLOv5 입력 전처리
    img = cv2.resize(frame, (640, 640))
    img_rgb = img[:, :, ::-1].copy()
    img_tensor = torch.from_numpy(img_rgb).float().permute(2, 0, 1) / 255.0
    img_tensor = img_tensor.unsqueeze(0).to(device)

    # 객체 탐지
    pred = model(img_tensor)
    pred = non_max_suppression(pred, conf_thres=0.4, iou_thres=0.5)[0]

    # Deep SORT 입력 준비
    track_inputs = []
    if pred is not None and len(pred):
        if isinstance(pred, torch.Tensor):
            pred = pred.cpu().numpy()

        for *xyxy, conf, cls in pred:
            x1, y1, x2, y2 = map(int, xyxy)

            # 🛡️ 경계 값 보정
            x1 = max(0, min(x1, frame.shape[1] - 1))
            y1 = max(0, min(y1, frame.shape[0] - 1))
            x2 = max(0, min(x2, frame.shape[1] - 1))
            y2 = max(0, min(y2, frame.shape[0] - 1))

            # 너무 작은 bbox는 건너뜀
            if x2 - x1 < 3 or y2 - y1 < 3:
                continue

            bbox = [x1, y1, x2 - x1, y2 - y1]
            track_inputs.append((bbox, float(conf), f'class_{int(cls)}'))

    # Deep SORT 업데이트
    tracks = []
    if len(track_inputs) > 0:
        try:
            tracks = tracker.update_tracks(track_inputs, frame=frame)
        except Exception as e:
            print("⚠️ Deep SORT 오류 발생, 건너뜀:", e)
            tracks = []

    # 시각화
    for track in tracks:
        if not track.is_confirmed():
            continue
        track_id = track.track_id
        x1, y1, x2, y2 = map(int, track.to_ltrb())
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f'ID {track_id}', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    out.write(frame)

cap.release()
out.release()
print("\n✅ 추적 완료! 결과 파일: output_tracking.mp4")

from google.colab import files
files.download("output_tracking.mp4")