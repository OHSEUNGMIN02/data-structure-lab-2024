# -*- coding: utf-8 -*-
"""Tracking

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNhpASqriTybmMtU1Pji-IzFsN4VP49-
"""

# ğŸ“¦ 1. ì„¤ì¹˜
!git clone https://github.com/ultralytics/yolov5.git
!pip install -r yolov5/requirements.txt
!pip install deep_sort_realtime

# ğŸ“ 2. YOLOv5 ëª¨ë¸ ë¡œë“œ (torch.hub ì‚¬ìš©)
import cv2
import torch
import numpy as np
import glob
import os
from deep_sort_realtime.deepsort_tracker import DeepSort
from google.colab import files

# ğŸ“¤ 3. ì´ë¯¸ì§€ ì—¬ëŸ¬ ì¥ ì—…ë¡œë“œ
print("ğŸ“¤ ì´ë¯¸ì§€ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì˜ˆ: frame001.jpg, frame002.jpg ë“±)")
uploaded = files.upload()

# ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ì •ë ¬
image_files = sorted([f for f in uploaded.keys() if f.lower().endswith(('.jpg', '.png'))])

# ë¹„ë””ì˜¤ë¡œ ë³€í™˜ (10fps ê¸°ì¤€)
first_frame = cv2.imread(image_files[0])
h, w, _ = first_frame.shape
video_path = 'temp_input_video.mp4'
out_vid = cv2.VideoWriter(video_path, cv2.VideoWriter_fourcc(*'mp4v'), 10, (w, h))
for f in image_files:
    frame = cv2.imread(f)
    out_vid.write(frame)
out_vid.release()
print("ğŸï¸ ì´ë¯¸ì§€ â†’ temp_input_video.mp4 ë³€í™˜ ì™„ë£Œ")

# ğŸ¯ YOLOv5 ëª¨ë¸ ë¡œë“œ (torch.hub)
device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True).to(device)
model.conf = 0.4
model.iou = 0.5

# ğŸ¯ Deep SORT ì´ˆê¸°í™”
tracker = DeepSort(max_age=30, n_init=3, max_cosine_distance=0.4)

# ğŸ“½ï¸ ë¹„ë””ì˜¤ ì—´ê¸° ë° ì¶œë ¥ ì„¤ì •
cap = cv2.VideoCapture(video_path)
width, height = int(cap.get(3)), int(cap.get(4))
fps = cap.get(cv2.CAP_PROP_FPS)
out = cv2.VideoWriter('output_tracking.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

print("\nğŸš€ ì¶”ì  ì‹œì‘...")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret or frame is None or frame.size == 0:
        break

    # ê°ì²´ íƒì§€
    results = model(frame)
    detections = results.xyxy[0].cpu().numpy()  # [x1, y1, x2, y2, conf, cls]

    # Deep SORT ì…ë ¥ ì¤€ë¹„
    track_inputs = []
    for det in detections:
        x1, y1, x2, y2, conf, cls = det
        x1, y1, x2, y2 = map(int, [x1, y1, x2, y2])

        # ğŸ›¡ï¸ ê²½ê³„ ë³´ì •
        x1 = max(0, min(x1, frame.shape[1] - 1))
        y1 = max(0, min(y1, frame.shape[0] - 1))
        x2 = max(0, min(x2, frame.shape[1] - 1))
        y2 = max(0, min(y2, frame.shape[0] - 1))
        if x2 - x1 < 3 or y2 - y1 < 3:
            continue

        bbox = [x1, y1, x2 - x1, y2 - y1]  # [x, y, w, h]
        track_inputs.append((bbox, conf, f'class_{int(cls)}'))

    tracks = []
    if len(track_inputs) > 0:
        try:
            tracks = tracker.update_tracks(track_inputs, frame=frame)
        except Exception as e:
            print("âš ï¸ Deep SORT ì˜¤ë¥˜ ë°œìƒ, ê±´ë„ˆëœ€:", e)
            tracks = []

    for track in tracks:
        if not track.is_confirmed():
            continue
        track_id = track.track_id
        x1, y1, x2, y2 = map(int, track.to_ltrb())
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f'ID {track_id}', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    out.write(frame)

cap.release()
out.release()
print("\nâœ… ì¶”ì  ì™„ë£Œ! ê²°ê³¼ íŒŒì¼: output_tracking.mp4")

from google.colab import files
files.download("output_tracking.mp4")